{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is composed of the following steps:\n",
    "* map each 3D single cell model into a graph using UMAP\n",
    "The UMAP construction is supposed to provide a robust graph representation of the 3D dataset, capturing the topology of the chromation conformation, being resilient to uncontrollable details of the HiC data generation and deconvolution\n",
    "* stack the graphs togher to create a 3-way tensor\n",
    "* decompose the 3-way tensor using a non-negative tensor factorization\n",
    "Efficient and easy to implement\n",
    "* the rank label of the decomposition identifies different communities\n",
    "A convenient form for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import umap\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import igraph\n",
    "from igraph import *\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load the dataset\n",
    "'''\n",
    "path = '/home/garner1/Work/dataset/gpseq/10000'\n",
    "files = os.listdir(path) # dir list in path with different configurations\n",
    "\n",
    "config_sample = random.sample(files, k=100) # sample k times without replacement from configurations\n",
    "\n",
    "array_list = [] #initialize array list\n",
    "count = 0\n",
    "for config in config_sample:\n",
    "    dirname = os.fsdecode(config)\n",
    "    filename = os.path.join(path, dirname+'/coords.csv_sparse_graph.npz')\n",
    "    if os.path.isfile(filename): \n",
    "        count += 1\n",
    "#         print(count,filename)\n",
    "        with open(filename, 'r') as f:\n",
    "            mat = scipy.sparse.load_npz(filename)\n",
    "#             print(check_symmetric(mat.todense()))\n",
    "            array_list.append(mat.todense())  # densify the sparse mat and add to list\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "'''\n",
    "Stack the networks together to generate a 3 way tensor\n",
    "'''\n",
    "T = np.array(array_list) # the final tensor kXnodesXnodes\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorly.backend as tb\n",
    "# from tensorly.tenalg.proximal import soft_thresholding\n",
    "\n",
    "# T_thresh = soft_thresholding(T, 0.9)\n",
    "# print(tl.min(T_thresh),tl.max(T_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decompose the tensor \n",
    "Output: is a list of factors each of shape \n",
    "The first weights the graph realizations, each col is associated to a rank value, shape: #realizations X Rank\n",
    "The second weights the membership of a node to a community/structured labeled by the rank index, shape: NxRank\n",
    "The third weights the membership of a node to a community/structured labeled by the rank index, shape: NxRank\n",
    "'''\n",
    "factors = non_negative_parafac(T, rank=100, verbose=1, tol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.shape for f in factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for comm in range(30):\n",
    "    weights.append(tl.norm(factors_2[0][:,comm])*tl.norm(factors_2[1][:,comm])*tl.norm(factors_22[2][:,comm]))\n",
    "np.histogram(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for comm in range(30):\n",
    "    weights.append(tl.norm(factors[0][:,comm])*tl.norm(factors[1][:,comm])*tl.norm(factors[2][:,comm]))\n",
    "np.histogram(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for comm in range(30):\n",
    "    a = factors_2[1][:,comm]\n",
    "    b = factors_2[2][:,comm]\n",
    "    mat_2 = np.outer(a,b)\n",
    "    plt.imshow(mat_2, cmap='Blues', interpolation='nearest')\n",
    "    plt.title(str(tl.norm(factors_2[0][:,comm])*tl.norm(factors_2[1][:,comm])*tl.norm(factors_2[2][:,comm])),fontsize=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for comm in range(30):\n",
    "    a = factors[1][:,comm]\n",
    "    b = factors[2][:,comm]\n",
    "    mat_1 = np.outer(a,b)\n",
    "    plt.imshow(mat_1, cmap='Blues', interpolation='nearest')\n",
    "    plt.title(str(tl.norm(factors[0][:,comm])*tl.norm(factors[1][:,comm])*tl.norm(factors[2][:,comm])),fontsize=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', rc={'figure.figsize':(50,50)})\n",
    "\n",
    "G = nx.from_scipy_sparse_matrix(scipy.sparse.coo_matrix(mat)) # if sparse matrix\n",
    "# pos = XYZ[:,:2]\n",
    "eset = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] >= 0.0]\n",
    "weights = [d['weight'] for (u, v, d) in G.edges(data=True)]\n",
    "# pos = nx.spectral_layout(G,weight='weight',dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_networkx_nodes(G, pos, alpha=1.0)\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=eset,alpha=1, width=10*weights,edge_color='r',style='solid')\n",
    "# nx.draw(G, pos = pos, edgelist=eset,alpha=1, width=10*weights,edge_color='r',style='solid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources, targets = mat.nonzero() # define i,j vertex set in links\n",
    "edgelist = list(zip(sources.tolist(), targets.tolist()))\n",
    "g = Graph(edgelist,edge_attrs={'weight': mat.data.tolist()})\n",
    "g = g.simplify(combine_edges=mean) #to remove the symmetric edges combine them as the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = g.community_fastgreedy(weights=g.es[\"weight\"]) #gives overlapping communities\n",
    "clust = comm.as_clustering()\n",
    "# print(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = g.community_leading_eigenvector(weights=g.es[\"weight\"])\n",
    "# print(comm.membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = g.community_walktrap(weights=g.es[\"weight\"], steps=4)\n",
    "clust = comm.as_clustering()\n",
    "# print(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = g.community_multilevel(weights=g.es[\"weight\"])\n",
    "print(comm.membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = g.community_spinglass(weights=g.es[\"weight\"]) #very slow\n",
    "print(comm.membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_clusters = [ind for ind in range(len(clust)) if len(clust[ind])>=0] #filter clusters by size\n",
    "number_of_colors = len(big_clusters)\n",
    "color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "sns.set(style='white', rc={'figure.figsize':(50,50)})\n",
    "count = 0\n",
    "for i in big_clusters:\n",
    "    List = [color[count],]*len(clust[i])\n",
    "    nx.draw_networkx_nodes(G, pos,nodelist=clust[i],alpha=0.5,node_color=List,node_size=500)\n",
    "    count += 1\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=eset,alpha=0.75, width=weights,edge_color='r',style='solid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
