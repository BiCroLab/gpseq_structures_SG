{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qmat(S,configuration,path):\n",
    "    dirname = os.fsdecode(configuration)\n",
    "    filename = os.path.join(path, dirname+'/coords.csv_sparse_graph.npz')\n",
    "    if os.path.isfile(filename): \n",
    "        A = scipy.sparse.load_npz(filename)\n",
    "        '''construct modularity matrix'''\n",
    "        M = A\n",
    "        k = A.sum(axis=0)\n",
    "        w = A.sum(axis=None)\n",
    "        M = A - np.outer(k,k)*0.5/w\n",
    "        output = M.shape[0]*M.shape[1]*np.trace(np.dot(np.dot(S.transpose(),M),S))/(2.0*w) #rescale by network size\n",
    "    return output\n",
    "\n",
    "def sample_modularity(S,cf_samples,path):\n",
    "    modularity_values = []\n",
    "    for configuration in cf_samples:\n",
    "            modularity_values.append(Qmat(S,configuration,path))  \n",
    "    return modularity_values\n",
    "\n",
    "def random_community(Sp,configuration,path):\n",
    "    np.random.shuffle(Sp)\n",
    "    return Qmat(Sp,configuration,path)\n",
    "\n",
    "def membership(factors):\n",
    "    S = np.zeros(shape=factors[1][1].shape)\n",
    "    for c in range(S.shape[1]):\n",
    "        vec = 0.5*(factors[1][1][:,c]+factors[1][2][:,c]) # take the average of the 2 factors, that should be identical\n",
    "        S[:,c] = vec/tl.norm(vec,1) #normalize membership\n",
    "    Sp = np.copy(S) # this copy can be used for significance testing\n",
    "    return S,Sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10 #numb of sampled 3d structured\n",
    "path = '/media/garner1/hdd1/gpseq/10000'\n",
    "configurations = os.listdir(path) \n",
    "config_sample = random.sample(configurations, k=samples) # sample k times without replacement from configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 3 # numb of components in svd. The greater this value the slower the parafac convergence \n",
    "comm = 3 # numb of communities to retrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.zeros(shape = (samples, 3043, 3043), dtype = np.float32)\n",
    "graph_idx = 0\n",
    "for config in config_sample:\n",
    "    dirname = os.fsdecode(config)\n",
    "    filename = os.path.join(path, dirname+'/coords.csv_tsvd.npz')\n",
    "    if os.path.isfile(filename): \n",
    "        svd = np.load(filename)\n",
    "        u = svd['u'][:,:rank]\n",
    "        s = svd['s'][:rank]\n",
    "        vt = svd['vt'][:rank,:]\n",
    "        T[graph_idx,:,:] = np.dot(np.dot(u,np.diag(s)),vt)\n",
    "        del svd\n",
    "        continue\n",
    "    else:\n",
    "        T[graph_idx,:,:] = np.zeros(shape = (3043,3043),)\n",
    "        continue\n",
    "    graph_idx += 1\n",
    "\n",
    "print(T.shape)   \n",
    "factors = non_negative_parafac(T, rank=comm, verbose=1, n_iter_max=20,tol=1e-08,init='svd')\n",
    "[factors[1][ind].shape for ind in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, Sp = membership(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = sample_modularity(S,config_sample,path) # S on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = sample_modularity(S,random.sample(os.listdir(path), k=100),path) # S on the test data\n",
    "mu_test = np.mean(h2); sigma_test = np.std(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "h3 = [random_community(Sp,config_sample[ind],path) for count in range(5) for ind in range(samples)] # random S on one of the training data\n",
    "mu_null = np.mean(h3); sigma_null = np.std(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "labels = ['training data','test data', 'null model']\n",
    "histos = [h1,h2,h3]\n",
    "fig, ax = plt.subplots()\n",
    "for count in range(3):\n",
    "#     sns.distplot(histos[count], kde=False,norm_hist=True,label=labels[count],hist_kws=dict(alpha=0.7))\n",
    "    sns.distplot(histos[count], rug=True, hist=False,label=labels[count])\n",
    "    \n",
    "\n",
    "ref = Qmat(S,config_sample[ind],path)\n",
    "# ax.axvline(ref,color='red',label='z-score: '+str(np.round((ref-mu)/sigma))) # draw a red vertical line at the value of S for the example graph\n",
    "plt.legend()\n",
    "plt.title('HiC only with model significance '+str(np.round((mu_test-mu_null)/(sigma_test+sigma_null))))\n",
    "# print('z-score is: '+str((ref-mu)/sigma))  # z-score for a random S as the null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(comm):\n",
    "    a = factors[1][1][:,i]\n",
    "    b = factors[1][2][:,i]\n",
    "    c = factors[1][0][:,i]\n",
    "    mat = np.outer(0.5*(a+b),0.5*(a+b)) # symmetrize wrt a & b\n",
    "    print(tl.norm(a,2)*tl.norm(b,2)*tl.norm(c,2))\n",
    "#     plt.imshow(mat, cmap='Blues', interpolation='nearest')\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(mat,cmap='Blues',square=True,xticklabels=False,yticklabels=False)\n",
    "    plt.show()  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 3\n",
    "dirname = os.fsdecode(config_sample[ind])\n",
    "filename = os.path.join(path, dirname+'/coords.csv_sparse_graph.npz')\n",
    "A = scipy.sparse.load_npz(filename).todense()\n",
    "sns.heatmap(A,cmap='Blues',square=True,xticklabels=False,yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(comm):\n",
    "    mat = np.outer(S[:,i],S[:,i]) # symmetrize wrt a & b\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(np.round(mat.shape[0]*mat.shape[1]*np.multiply(mat,A),decimals=3),square=True,xticklabels=False,yticklabels=False)\n",
    "    plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
